# -------------------------------------------------
#  LLM 共通
# -------------------------------------------------
model: dummy-llm
temperature: 0
max_tokens: 256


