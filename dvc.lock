schema: '2.0'
stages:
  evaluate:
    cmd: python -m run.evaluate
    deps:
    - path: data/
      hash: md5
      md5: 26afe518d513bb3b3da61c889b5a4ce2.dir
      size: 1158
      nfiles: 1
    - path: src/sample_judge/prompt
      hash: md5
      md5: 1427533ff7947135278d60a7918c5668.dir
      size: 385
      nfiles: 2
    - path: src/sample_judge/rule_base_judge
      hash: md5
      md5: d751713988987e9331980363e24189ce.dir
      size: 0
      nfiles: 0
    outs:
    - path: result/result.csv
      hash: md5
      md5: f5b5c9a18e78458d1a2fdd35d4096e10
      size: 5684
  rulebase_evaluate@count_text_length:
    cmd: python -m run.rulebase_evaluate --rulebase_func_name count_text_length 
      --submit_file_name data_set_idol_discription
    deps:
    - path: data/submit/data_set_idol_discription.csv
      hash: md5
      md5: b029b8d7b029272ece4474743df5058f
      size: 1260
    - path: run/rulebase_evaluate.py
      hash: md5
      md5: 1b5cf17cf1ddcb62d26eb7df59a18a35
      size: 1665
    - path: src/judge/rulebase_funcs/count_text_length.py
      hash: md5
      md5: 055b0c892221991b62284da516344de5
      size: 356
    outs:
    - path: 
        data/result/rulebase_data_set_idol_discription_count_text_length.json
      hash: md5
      md5: bb86efe65cff0776e0523e9d44db63b3
      size: 1421
  rulebase_evaluate@check_megu_in_text:
    cmd: python -m run.rulebase_evaluate --rulebase_func_name check_megu_in_text
      --submit_file_name data_set_idol_discription
    deps:
    - path: data/submit/data_set_idol_discription.csv
      hash: md5
      md5: b029b8d7b029272ece4474743df5058f
      size: 1260
    - path: run/rulebase_evaluate.py
      hash: md5
      md5: 1b5cf17cf1ddcb62d26eb7df59a18a35
      size: 1665
    - path: src/judge/rulebase_funcs/check_megu_in_text.py
      hash: md5
      md5: a05c349a92ce22b233956445f5ab403b
      size: 380
    outs:
    - path: 
        data/result/rulebase_data_set_idol_discription_check_megu_in_text.json
      hash: md5
      md5: 0f83d98acf9f6b28d46769baaefe4d7f
      size: 1421
  llm_evaluate@check_if_category_in_text:
    cmd: python -m run.llm_evaluate --prompt_name check_if_category_in_text 
      --submit_file_name data_set_idol_discription
    deps:
    - path: data/submit/data_set_idol_discription.csv
      hash: md5
      md5: b029b8d7b029272ece4474743df5058f
      size: 1260
    - path: run/llm_evaluate.py
      hash: md5
      md5: 9c6b300e517da504c132b6e13a975b7d
      size: 1929
    - path: src/judge/prompt/check_if_category_in_text.txt
      hash: md5
      md5: 2d6d66c9c29a288f2114d7cbd0a9a078
      size: 183
    outs:
    - path: 
        data/result/llm_data_set_idol_discription_check_if_category_in_text.json
      hash: md5
      md5: e09b11786e42990e9a1710145fba7b29
      size: 1514
  llm_evaluate@check_if_gakunen_in_text:
    cmd: python -m run.llm_evaluate --prompt_name check_if_gakunen_in_text 
      --submit_file_name data_set_idol_discription
    deps:
    - path: data/submit/data_set_idol_discription.csv
      hash: md5
      md5: b029b8d7b029272ece4474743df5058f
      size: 1260
    - path: run/llm_evaluate.py
      hash: md5
      md5: 9c6b300e517da504c132b6e13a975b7d
      size: 1929
    - path: src/judge/prompt/check_if_gakunen_in_text.txt
      hash: md5
      md5: b2c196a574b01de1914f29010f3f4fc6
      size: 184
      isexec: true
    outs:
    - path: 
        data/result/llm_data_set_idol_discription_check_if_gakunen_in_text.json
      hash: md5
      md5: e09b11786e42990e9a1710145fba7b29
      size: 1514
  make_dashboard:
    cmd: poetry run python -m run.make_dashboard
    deps:
    - path: data/result/
      hash: md5
      md5: 261a0d6c68fffba069d4659df3b83a66.dir
      size: 11188
      nfiles: 8
    - path: run/make_dashboard.py
      hash: md5
      md5: 7da77944ff1198fb2b6f398b2171a1fd
      size: 540
    outs:
    - path: data/dashboard/mikoto_run_ids.csv
      hash: md5
      md5: 5a95ab5e22f51576bfc11ec804b8d1ff
      size: 565
    - path: data/dashboard/scores.csv
      hash: md5
      md5: 03e1a7e0bd7b83054cfd5c602ac4229c
      size: 558
  llm_generate:
    cmd: poetry run python -m run.llm_generate --generate_target_name data 
      --prompt_name set_idol_discription
    deps:
    - path: data/generate_target/data.csv
      hash: md5
      md5: fbf274e04fdb7adc0b2fafbf175e220f
      size: 97
    - path: run/llm_generate.py
      hash: md5
      md5: cd71335478a0d84de5c6c371203862ea
      size: 1901
    - path: src/generate/prompt/set_idol_discription.txt
      hash: md5
      md5: 1af23e379e5f70f2aeb56a2c0d9bfcc8
      size: 127
    params:
      params.yaml:
        generate:
          generate_data_name: data
          generate_prompt_name: set_idol_discription
          model_config:
            model: gpt-3.5-turbo
    outs:
    - path: data/submit/data_set_idol_discription.csv
      hash: md5
      md5: bc6f0ef95ef236651dcb00787bac18bb
      size: 1260
